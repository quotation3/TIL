{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFIDF class만들기.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOiZHBzX2eqviARnGDFGqm6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quotation3/TIL/blob/master/TFIDF_class%ED%99%94.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNBXEmWeTeej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiZ0OXXuJ21O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TFIDF:\n",
        "\n",
        "    def __init__(self, text):\n",
        "        self.text = text\n",
        "        self.tokens = []\n",
        "        self.tf_list = []\n",
        "        self.idf_list = []\n",
        "\n",
        "    def make_tf(self):\n",
        "\n",
        "        sentence_tokens = []\n",
        "        cnt_list = []\n",
        "        total_tokens = []\n",
        "\n",
        "        # 텍스트별 토큰, 문장전체 토큰 리스트\n",
        "        for sentence in self.text:\n",
        "            tmp = []\n",
        "            tmp.append(sentence.split())\n",
        "            sentence_tokens.extend(tmp)\n",
        "            self.tokens.extend(sentence.split())\n",
        "        self.tokens = list(set(self.tokens))\n",
        "\n",
        "        # 빈도수 리스트 생성\n",
        "        for i in range(len(text)):\n",
        "            cnt_list.append([0 for j in range(len(self.tokens))])\n",
        "            for j in range(len(sentence_tokens[i])):\n",
        "                for k in range(len(self.tokens)):\n",
        "                    if self.tokens[k]==sentence_tokens[i][j]:\n",
        "                        cnt_list[i][k]+=1\n",
        "\n",
        "            total_tokens.append([len(sentence_tokens[i]) for j in range(len(self.tokens))])\n",
        "\n",
        "        # tf 리스트 생성\n",
        "        for i in range(len(text)):\n",
        "            self.tf_list.append([0 for j in range(len(self.tokens))]) \n",
        "            for j in range(len(self.tokens)):\n",
        "                self.tf_list[i][j] = cnt_list[i][j]/len(sentence_tokens[i])\n",
        "\n",
        "        # 데이터프레임 결과도출\n",
        "        for i in range(len(text)):\n",
        "            print('문서{}'.format(i+1))\n",
        "            data=np.array([cnt_list[i], total_tokens[i], self.tf_list[i]])\n",
        "            print(pd.DataFrame(data.T, index=self.tokens, columns=['문서내토큰빈도','문서내전체토큰','TF']))\n",
        "\n",
        "\n",
        "    def make_idf(self):\n",
        "\n",
        "        # 문서수 리스트 생성\n",
        "        text_num_list = [len(self.text) for i in range(len(self.tokens))]\n",
        "\n",
        "        # 토큰이 등장한 문서수 리스트 생성\n",
        "        token_in_text = [0 for i in range(len(self.tokens))]\n",
        "        for i in range(len(self.tokens)):\n",
        "            for j in range(len(self.text)):\n",
        "                if self.tokens[i] in self.text[j]:\n",
        "                    token_in_text[i]+=1\n",
        "        # IDF 리스트 생성\n",
        "        for i in range(len(self.tokens)):\n",
        "            self.idf_list.append(np.log(text_num_list[i]/token_in_text[i]))\n",
        "\n",
        "        # 데이터프레임 결과도출\n",
        "        data=np.array([text_num_list, token_in_text, self.idf_list])\n",
        "        print(pd.DataFrame(data.T, index=self.tokens, columns=['문서수','토큰이 등장한 문서수','IDF']))\n",
        "\n",
        "\n",
        "    def make_tfidf(self):\n",
        "\n",
        "        # TFIDF 리스트 생성\n",
        "        tfidf_list = []\n",
        "        for i in range(len(self.text)):\n",
        "            tfidf_list.append(np.array(self.tf_list[i])*np.array(idf_list))\n",
        "\n",
        "        # 최종 데이터프레임 결과도출\n",
        "        for i in range(len(self.text)):\n",
        "            print('문서{}'.format(i+1))\n",
        "            data=np.array([self.tf_list[i],self.idf_list, tfidf_list[i]])\n",
        "            print(pd.DataFrame(data.T, index=self.tokens, columns=['TF','IDF','TF-IDF']))\n"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eK4Bf_fJ1qu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d1 = 'The cat sat on my face i hate a cat'\n",
        "d2 = 'The dog sat on my bed i love a dog'\n",
        "text = [d1,d2]"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3iU-Q-a0S60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf = TFIDF(text)"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhGqSc-f0ZmZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "d93a3a44-ab46-4443-b42d-c7fffd15f7b1"
      },
      "source": [
        "tfidf.make_tf()"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "문서1\n",
            "      문서내토큰빈도  문서내전체토큰   TF\n",
            "my        1.0     10.0  0.1\n",
            "face      1.0     10.0  0.1\n",
            "i         1.0     10.0  0.1\n",
            "cat       2.0     10.0  0.2\n",
            "hate      1.0     10.0  0.1\n",
            "bed       0.0     10.0  0.0\n",
            "sat       1.0     10.0  0.1\n",
            "love      0.0     10.0  0.0\n",
            "a         1.0     10.0  0.1\n",
            "dog       0.0     10.0  0.0\n",
            "on        1.0     10.0  0.1\n",
            "The       1.0     10.0  0.1\n",
            "문서2\n",
            "      문서내토큰빈도  문서내전체토큰   TF\n",
            "my        1.0     10.0  0.1\n",
            "face      0.0     10.0  0.0\n",
            "i         1.0     10.0  0.1\n",
            "cat       0.0     10.0  0.0\n",
            "hate      0.0     10.0  0.0\n",
            "bed       1.0     10.0  0.1\n",
            "sat       1.0     10.0  0.1\n",
            "love      1.0     10.0  0.1\n",
            "a         1.0     10.0  0.1\n",
            "dog       2.0     10.0  0.2\n",
            "on        1.0     10.0  0.1\n",
            "The       1.0     10.0  0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiSRvmpA0cet",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "ac7472b4-c8d8-4e2c-eb67-09554a03ce4e"
      },
      "source": [
        "tfidf.make_idf()"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      문서수  토큰이 등장한 문서수       IDF\n",
            "my    2.0          2.0  0.000000\n",
            "face  2.0          1.0  0.693147\n",
            "i     2.0          2.0  0.000000\n",
            "cat   2.0          1.0  0.693147\n",
            "hate  2.0          1.0  0.693147\n",
            "bed   2.0          1.0  0.693147\n",
            "sat   2.0          2.0  0.000000\n",
            "love  2.0          1.0  0.693147\n",
            "a     2.0          2.0  0.000000\n",
            "dog   2.0          1.0  0.693147\n",
            "on    2.0          2.0  0.000000\n",
            "The   2.0          2.0  0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lek1cFqv0fKl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "6d8a18ad-6d39-4b57-902c-18c382e01a09"
      },
      "source": [
        "tfidf.make_tfidf()"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "문서1\n",
            "       TF       IDF    TF-IDF\n",
            "my    0.1  0.000000  0.000000\n",
            "face  0.1  0.693147  0.069315\n",
            "i     0.1  0.000000  0.000000\n",
            "cat   0.2  0.693147  0.138629\n",
            "hate  0.1  0.693147  0.069315\n",
            "bed   0.0  0.693147  0.000000\n",
            "sat   0.1  0.000000  0.000000\n",
            "love  0.0  0.693147  0.000000\n",
            "a     0.1  0.000000  0.000000\n",
            "dog   0.0  0.693147  0.000000\n",
            "on    0.1  0.000000  0.000000\n",
            "The   0.1  0.000000  0.000000\n",
            "문서2\n",
            "       TF       IDF    TF-IDF\n",
            "my    0.1  0.000000  0.000000\n",
            "face  0.0  0.693147  0.000000\n",
            "i     0.1  0.000000  0.000000\n",
            "cat   0.0  0.693147  0.000000\n",
            "hate  0.0  0.693147  0.000000\n",
            "bed   0.1  0.693147  0.069315\n",
            "sat   0.1  0.000000  0.000000\n",
            "love  0.1  0.693147  0.069315\n",
            "a     0.1  0.000000  0.000000\n",
            "dog   0.2  0.693147  0.138629\n",
            "on    0.1  0.000000  0.000000\n",
            "The   0.1  0.000000  0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}